{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import os\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, learning_curve\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_attack_1 = pd.read_csv('../dataset/Network datatset/csv/attack_1.csv', sep=\",\")\n",
    "network_attack_2 = pd.read_csv('../dataset/Network datatset/csv/attack_2.csv', sep=\",\")\n",
    "network_attack_3 = pd.read_csv('../dataset/Network datatset/csv/attack_3.csv', sep=\",\")\n",
    "network_attack_4 = pd.read_csv('../dataset/Network datatset/csv/attack_4.csv', sep=\",\")\n",
    "network_normal = pd.read_csv('../dataset/Network datatset/csv/normal.csv', sep=\",\")\n",
    "\n",
    "df_att1 = pd.read_csv(\"../dataset/Physical dataset/phy_att_1.csv\", encoding = 'UTF-16', sep=\"\\t\")\n",
    "df_att2 = pd.read_csv(\"../dataset/Physical dataset/phy_att_2.csv\", encoding = 'UTF-16', sep=\"\\t\")\n",
    "df_att3 = pd.read_csv(\"../dataset/Physical dataset/phy_att_3.csv\", encoding = 'UTF-16', sep=\"\\t\")\n",
    "df_att4 = pd.read_csv(\"../dataset/Physical dataset/phy_att_4.csv\", sep=\",\")\n",
    "df_norm = pd.read_csv(\"../dataset/Physical dataset/phy_norm.csv\", encoding = 'UTF-16', sep=\"\\t\")\n",
    "\n",
    "df_att1.name = \"df_att1\"\n",
    "df_att2.name = \"df_att2\"\n",
    "df_att3.name = \"df_att3\"\n",
    "df_att4.name = \"df_att4\"\n",
    "df_norm.name = \"df_norm\"\n",
    "network_attack_1.name = \"network_attack_1\"\n",
    "network_attack_2.name = \"network_attack_2\"\n",
    "network_attack_3.name = \"network_attack_3\"\n",
    "network_attack_4.name = \"network_attack_4\"\n",
    "network_normal.name = \"network_normal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = [df_att1, df_att2, df_att3, df_att4, df_norm, network_attack_1, network_attack_2, network_attack_3, network_attack_4, network_normal]\n",
    "def df_all_fn(func):\n",
    "    df_all = [df_att1, df_att2, df_att3, df_att4, df_norm, network_attack_1, network_attack_2, network_attack_3, network_attack_4, network_normal]\n",
    "    for df in df_all:\n",
    "        print(df.name)\n",
    "        print(\"\\n\" + df.name + \" -------------------------------------\")\n",
    "        func(df)\n",
    "\n",
    "df_all_net = [network_attack_1, network_attack_2, network_attack_3, network_attack_4, network_normal]\n",
    "def df_all_net_fn(func):\n",
    "    df_all_net = [network_attack_1, network_attack_2, network_attack_3, network_attack_4, network_normal]\n",
    "    for df in df_all_net:\n",
    "        print(df.name)\n",
    "        print(\"\\n\" + df.name + \" -------------------------------------\")\n",
    "        func(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transform\n",
    "\n",
    "# df_net_att2['Time'] = pd.to_datetime(df_net_att2['Time'], format='mixed')\n",
    "# df_phys_att2['Time'] = pd.to_datetime(df_phys_att2['Time'], format='mixed')\n",
    "# df_net_att2['Time'] = df_net_att2['Time'].dt.floor('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(df_all):\n",
    "    df_all[i] = df_all[i].rename(columns = {'Time':'time'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_attack_1.columns = network_attack_1.columns.str.strip()\n",
    "network_attack_2.columns = network_attack_2.columns.str.strip()\n",
    "network_attack_3.columns = network_attack_3.columns.str.strip()\n",
    "network_attack_4.columns = network_attack_4.columns.str.strip()\n",
    "network_normal.columns = network_normal.columns.str.strip()\n",
    "\n",
    "df_att1.columns = df_att1.columns.str.strip()\n",
    "df_att2.columns = df_att2.columns.str.strip()\n",
    "df_att3.columns = df_att3.columns.str.strip()\n",
    "df_att4.columns = df_att4.columns.str.strip()\n",
    "df_norm.columns = df_norm.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                time              mac_s              mac_d  \\\n",
       "0        2021-04-09 18:23:28.385003  74:46:a0:bd:a7:1b  0a:fe:ec:47:74:fb   \n",
       "1        2021-04-09 18:23:28.385005  74:46:a0:bd:a7:1b  e6:3f:ac:c9:a8:8c   \n",
       "2        2021-04-09 18:23:28.385006  74:46:a0:bd:a7:1b  fa:00:bc:90:d7:fa   \n",
       "3        2021-04-09 18:23:28.385484  0a:fe:ec:47:74:fb  74:46:a0:bd:a7:1b   \n",
       "4        2021-04-09 18:23:28.385486  fa:00:bc:90:d7:fa  74:46:a0:bd:a7:1b   \n",
       "...                             ...                ...                ...   \n",
       "5527404  2021-04-09 19:03:47.660871  74:46:a0:bd:a7:1b  0a:fe:ec:47:74:fb   \n",
       "5527405  2021-04-09 19:03:47.660871  74:46:a0:bd:a7:1b  00:80:f4:03:fb:12   \n",
       "5527406  2021-04-09 19:03:47.661288  fa:00:bc:90:d7:fa  74:46:a0:bd:a7:1b   \n",
       "5527407  2021-04-09 19:03:47.661290  e6:3f:ac:c9:a8:8c  74:46:a0:bd:a7:1b   \n",
       "5527408  2021-04-09 19:03:47.661291  0a:fe:ec:47:74:fb  74:46:a0:bd:a7:1b   \n",
       "\n",
       "                 ip_s          ip_d    sport    dport   proto    flags  size  \\\n",
       "0         84.3.251.20  84.3.251.102  56667.0    502.0  Modbus  11000.0    66   \n",
       "1         84.3.251.20  84.3.251.101  56666.0    502.0  Modbus  11000.0    66   \n",
       "2         84.3.251.20  84.3.251.103  56668.0    502.0  Modbus  11000.0    66   \n",
       "3        84.3.251.102   84.3.251.20    502.0  56667.0  Modbus  11000.0    64   \n",
       "4        84.3.251.103   84.3.251.20    502.0  56668.0  Modbus  11000.0    64   \n",
       "...               ...           ...      ...      ...     ...      ...   ...   \n",
       "5527404   84.3.251.20  84.3.251.102  56667.0    502.0  Modbus  11000.0    66   \n",
       "5527405   84.3.251.20   84.3.251.18  56665.0    502.0  Modbus  11000.0    66   \n",
       "5527406  84.3.251.103   84.3.251.20    502.0  56668.0  Modbus  11000.0    65   \n",
       "5527407  84.3.251.101   84.3.251.20    502.0  56666.0  Modbus  11000.0    64   \n",
       "5527408  84.3.251.102   84.3.251.20    502.0  56667.0  Modbus  11000.0    65   \n",
       "\n",
       "                               modbus_fn  n_pkt_src  n_pkt_dst  \\\n",
       "0                     Read Coils Request        0.0        0.0   \n",
       "1                     Read Coils Request        1.0        0.0   \n",
       "2                     Read Coils Request        2.0        0.0   \n",
       "3                    Read Coils Response        0.0        0.0   \n",
       "4                    Read Coils Response        0.0        1.0   \n",
       "...                                  ...        ...        ...   \n",
       "5527404           Read Holding Registers       37.0        9.0   \n",
       "5527405               Read Coils Request       38.0       20.0   \n",
       "5527406  Read Holding Registers Response        9.0       36.0   \n",
       "5527407              Read Coils Response       21.0       37.0   \n",
       "5527408  Read Holding Registers Response        9.0       38.0   \n",
       "\n",
       "        modbus_response  label_n   label  \n",
       "0                   NaN        0  normal  \n",
       "1                   NaN        0  normal  \n",
       "2                   NaN        0  normal  \n",
       "3                   [0]        0  normal  \n",
       "4                   [0]        0  normal  \n",
       "...                 ...      ...     ...  \n",
       "5527404             NaN        0  normal  \n",
       "5527405             NaN        0  normal  \n",
       "5527406             [0]        0  normal  \n",
       "5527407             [0]        0  normal  \n",
       "5527408             [0]        0  normal  \n",
       "\n",
       "[5527409 rows x 16 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_attack_1.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network_attack_1\n",
      "\n",
      "network_attack_1 -------------------------------------\n",
      "modbus_response dropped for network_attack_1\n",
      "network_attack_2\n",
      "\n",
      "network_attack_2 -------------------------------------\n",
      "modbus_response dropped for network_attack_2\n",
      "network_attack_3\n",
      "\n",
      "network_attack_3 -------------------------------------\n",
      "modbus_response dropped for network_attack_3\n",
      "network_attack_4\n",
      "\n",
      "network_attack_4 -------------------------------------\n",
      "modbus_response dropped for network_attack_4\n",
      "network_normal\n",
      "\n",
      "network_normal -------------------------------------\n",
      "modbus_response dropped for network_normal\n"
     ]
    }
   ],
   "source": [
    "# As there is too much na and [0] values, the column isn't representative so we drop it\n",
    "def drop_modbus_response(df):\n",
    "    del df['modbus_response']\n",
    "    print(\"modbus_response dropped for\", df.name)\n",
    "\n",
    "df_all_net_fn(drop_modbus_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates without counting the time column, that is unique\n",
    "# There is no duplicate when only ignoring the \"time\" column\n",
    "\n",
    "network_attack_1.drop_duplicates(subset=network_attack_1.columns.difference(['time']), inplace=True)\n",
    "network_attack_2.drop_duplicates(subset=network_attack_2.columns.difference(['time']), inplace=True)\n",
    "network_attack_3.drop_duplicates(subset=network_attack_3.columns.difference(['time']), inplace=True)\n",
    "network_attack_4.drop_duplicates(subset=network_attack_4.columns.difference(['time']), inplace=True)\n",
    "network_normal.drop_duplicates(subset=network_normal.columns.difference(['time']), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_att1.drop_duplicates(subset=df_att1.columns.difference(['time']), inplace=True)\n",
    "df_att2.drop_duplicates(subset=df_att2.columns.difference(['time']), inplace=True)\n",
    "df_att3.drop_duplicates(subset=df_att3.columns.difference(['time']), inplace=True)\n",
    "df_att4.drop_duplicates(subset=df_att4.columns.difference(['time']), inplace=True)\n",
    "df_norm.drop_duplicates(subset=df_norm.columns.difference(['time']), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From further informations, we can see that modbus_fn is always NaN for these attacks, so we replace the NaN by \"Not specified\".\n",
    "def change_column(col_name, value_to_replace):\n",
    "    df_all_net = [network_attack_1, network_attack_2, network_attack_3, network_attack_4, network_normal]\n",
    "    for df in df_all_net:\n",
    "        if value_to_replace == \"median\":\n",
    "            df[col_name] = df[col_name].fillna(df[col_name].median())\n",
    "        else:\n",
    "            df[col_name] = df[col_name].fillna(value_to_replace)\n",
    "\n",
    "change_column('modbus_fn', \"Not specified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do the same for other columns\n",
    "change_column('ip_d', \"Not specified\")\n",
    "change_column('ip_s', \"Not specified\")\n",
    "\n",
    "# We replace by the median\n",
    "change_column('sport', \"median\")\n",
    "change_column('dport', \"median\")\n",
    "change_column('n_pkt_src', \"median\")\n",
    "change_column('n_pkt_dst', \"median\")\n",
    "change_column('flags', \"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['normal' 'anomaly' 'scan' 'DoS' 'physical fault' 'MITM']\n"
     ]
    }
   ],
   "source": [
    "# Finally, as we don't want NA values in our dataset (some algorithms don't support them), we will drop them and check if there is still all attacks available\n",
    "# We don't care about sport and dport columns, as we are not going to use them later\n",
    "network_attack_1.dropna(how='any', inplace=True, subset=network_attack_1.columns.difference(['sport', 'dport']))\n",
    "network_attack_2.dropna(how='any', inplace=True, subset=network_attack_1.columns.difference(['sport', 'dport']))\n",
    "network_attack_3.dropna(how='any', inplace=True, subset=network_attack_1.columns.difference(['sport', 'dport']))\n",
    "network_attack_4.dropna(how='any', inplace=True, subset=network_attack_1.columns.difference(['sport', 'dport']))\n",
    "network_normal.dropna(how='any', inplace=True, subset=network_attack_1.columns.difference(['sport', 'dport']))\n",
    "\n",
    "df_att1.dropna(how='any', inplace=True, subset=df_att1.columns.difference(['sport', 'dport']))\n",
    "df_att2.dropna(how='any', inplace=True, subset=df_att2.columns.difference(['sport', 'dport']))\n",
    "df_att3.dropna(how='any', inplace=True, subset=df_att3.columns.difference(['sport', 'dport']))\n",
    "df_att4.dropna(how='any', inplace=True, subset=df_att4.columns.difference(['sport', 'dport']))\n",
    "df_norm.dropna(how='any', inplace=True, subset=df_norm.columns.difference(['sport', 'dport']))\n",
    "print(network_attack_2[\"label\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = [df_att1, df_att2, df_att3, df_att4, df_norm, network_attack_1, network_attack_2, network_attack_3, network_attack_4, network_normal]\n",
    "data_fusion_phys = pd.concat([df_att1, df_att2, df_att3, df_att4, df_norm])\n",
    "data_fusion_net = pd.concat([network_attack_1, network_attack_2, network_attack_3, network_attack_4, network_normal])\n",
    "data_fusion = pd.merge(data_fusion_phys, data_fusion_net, on='time', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_fusion['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We normalize the numerical data that don't act as a category. For example, a sport is a numerical category but nb_pkt_src is purely numerical\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_fusion_numerical = data_fusion[['size', 'n_pkt_src', 'n_pkt_dst']]\n",
    "data_fusion_numerical = pd.DataFrame(scaler.fit_transform(data_fusion_numerical), columns=data_fusion_numerical.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding the categorical data and numerical data that acts as a category\n",
    "data_fusion_one_hot_encoded = data_fusion\n",
    "# We don't care about label for now, we are going to add it later\n",
    "# We also delete sport and dport because after the one-hot encoding, we get 64000 more columns which creates a dataset of 70 GB\n",
    "data_fusion_one_hot_encoded = pd.get_dummies(data_fusion_one_hot_encoded[['mac_s', 'mac_d', 'ip_s', 'ip_d', 'proto', 'flags', 'size', 'modbus_fn']], columns=['mac_s', 'mac_d', 'ip_s', 'ip_d', 'proto', 'flags', 'size', 'modbus_fn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fusion_one_hot_encoded_and_normalized = pd.concat([data_fusion_numerical, data_fusion_one_hot_encoded], axis=1)\n",
    "# Datasets provided in SVM should not contain one-hot encoded data\n",
    "data_fusion_svm = pd.concat([data_fusion_numerical, data_fusion.copy().drop(columns=data_fusion_numerical.columns)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y= data_fusion['label']\n",
    "X= data_fusion_one_hot_encoded_and_normalized\n",
    "\n",
    "# Y_train_SVM and Y_test_SVM contains the label not one-hot encoded because it doesn't needs it\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "Y_test_svm=np.ravel(Y_test) \n",
    "Y_train_svm=np.ravel(Y_train)\n",
    "\n",
    "Y_train= pd.get_dummies(Y_train, columns=['label'])\n",
    "Y_test= pd.get_dummies(Y_test, columns=['label'])\n",
    "DataSet={\"X_train\": X_train, \"X_test\":X_test, \"Y_train\":Y_train, \"Y_test\":Y_test,'Y_train_svm':Y_train_svm,'Y_test_svm':Y_test_svm}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying some algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_to_label(one_hot_array):\n",
    "    return np.argmax(one_hot_array, axis=1)\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes, is_svm=False):\n",
    "    if not is_svm:\n",
    "        y_true = one_hot_to_label(y_true)\n",
    "        y_pred = one_hot_to_label(y_pred)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(len(classes), len(classes)))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "    \n",
    "    plt.title('Matrice de Confusion')\n",
    "    plt.xlabel('Valeurs Prédites')\n",
    "    plt.ylabel('Valeurs Réelles')\n",
    "    return plt\n",
    "    \n",
    "def plot_learning_curve_f1(estimator, X, y, cv=None, n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(\"Courbes d'apprentissage\")\n",
    "    plt.xlabel(\"Taille de l'échantillon d'apprentissage\")\n",
    "    plt.ylabel(\"F1 score\")\n",
    "    # Utiliser la fonction learning_curve avec le paramètre scoring='f1_micro' pour calculer le f1 score moyen sur chaque sous-ensemble\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring='f1_macro')\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"F1 score sur l'ensemble d'apprentissage\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"F1 score sur l'ensemble de validation croisée\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def Models(model, DataSet):\n",
    "    resultat_model = {}\n",
    "    \n",
    "    start_fit = time.time()\n",
    "\n",
    "    if model == 'cart':\n",
    "        parameters = {'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10]}\n",
    "        Model_cart = GridSearchCV(tree.DecisionTreeClassifier(), parameters, cv=5)\n",
    "        Model_cart.fit(DataSet['X_train'], DataSet['Y_train'])\n",
    "        resultat_model['cart'] = Model_cart.best_estimator_\n",
    "\n",
    "    elif model == 'xgb':\n",
    "        parameters = {'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.1, 0.2], 'n_estimators': [50, 100, 200]}\n",
    "        Model_XGBC = GridSearchCV(xgb.XGBClassifier(), parameters, cv=5)\n",
    "        Model_XGBC.fit(DataSet['X_train'], DataSet['Y_train'])\n",
    "        resultat_model['xgb'] = Model_XGBC.best_estimator_\n",
    "\n",
    "    elif model == 'knn':\n",
    "        parameters = {'n_neighbors': [3, 5, 7]}\n",
    "        Model_knn = GridSearchCV(KNeighborsClassifier(), parameters, cv=5)\n",
    "        Model_knn.fit(DataSet['X_train'], DataSet['Y_train'])\n",
    "        resultat_model['knn'] = Model_knn.best_estimator_\n",
    "\n",
    "    elif model == 'svm':\n",
    "        Model_svm =SVC(kernel='poly', degree=5)\n",
    "        Model_svm.fit(DataSet['X_train'],DataSet[\"Y_train_svm\"])\n",
    "        resultat_model['svm']=Model_svm\n",
    "        \n",
    "        \n",
    "    elif model == 'mlp':\n",
    "        parameters = {'hidden_layer_sizes': [(100,), (200,)]}\n",
    "        Model_mlp = GridSearchCV(MLPClassifier(), parameters, cv=5)\n",
    "        Model_mlp.fit(DataSet['X_train'], DataSet['Y_train'])\n",
    "        resultat_model[\"mlp\"] = Model_mlp.best_estimator_\n",
    "\n",
    "    elif model == 'randomForest':\n",
    "        parameters = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30]}\n",
    "        Model_rf = GridSearchCV(RandomForestClassifier(), parameters, cv=5)\n",
    "        Model_rf.fit(DataSet['X_train'], DataSet['Y_train'])\n",
    "        resultat_model['randomForest'] = Model_rf.best_estimator_\n",
    "\n",
    "    else:\n",
    "        print(\"Le nom du modèle doit être compris dans cette liste : {cart, xgb, knn, svm, mlp, randomForest}\")\n",
    "    end_fit = time.time()\n",
    "    elapsed_time = math.floor(end_fit - start_fit) + 1\n",
    "    return resultat_model, elapsed_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "if not os.path.exists('results'):\n",
    "    os.makedirs('results/concat/')\n",
    "\n",
    "def evaluate_models(DataSet):\n",
    "        \n",
    "    sizes = [100, 1000, 10000, 100000]\n",
    "    label=['Label_DoS', 'Label_MITM', 'Label_normal', 'Label_physical fault', 'Label_anomaly', 'Label_scan']\n",
    "\n",
    "    performance_results = {} # dictionnaire pour stocker les performances pour chaque modèle et chaque taille\n",
    "\n",
    "    for size in sizes:\n",
    "        subset_X_train = DataSet['X_train'][:size]\n",
    "        subset_Y_train = DataSet['Y_train'][:size]\n",
    "        subset_Y_train_svm = DataSet['Y_train_svm'][:size]\n",
    "\n",
    "        # Création des modèles \n",
    "        print('\\n')\n",
    "        print('data SIZE:',size)\n",
    "        print('\\n')\n",
    "        for model_type in ['cart', 'xgb', 'knn', 'randomForest', 'mlp', 'svm']:\n",
    "                \n",
    "            # Entraînez le modèle\n",
    "            model_dict, fit_time = Models(model_type, {'X_train': subset_X_train, 'Y_train': subset_Y_train,'Y_train_svm': subset_Y_train_svm})\n",
    "            model = model_dict[model_type]  # Accédez au modèle spécifique dans le dictionnaire\n",
    "            \n",
    "            #prédictions sur l'ensemble de test\n",
    "            predictions = model.predict(DataSet['X_test'])\n",
    "\n",
    "            start_predict = time.time()\n",
    "            predictions = model.predict(DataSet['X_test'])\n",
    "            end_predict = time.time()\n",
    "            pred_time = math.floor(end_predict - start_predict) + 1\n",
    "            \n",
    "            print(\"FIT TIME\")\n",
    "            print(fit_time)\n",
    "            print(\"PRED TIME\")\n",
    "            print(pred_time)\n",
    "\n",
    "            print(f\"{model_type}_size_{size}\")\n",
    "\n",
    "            image_path = \"results/concat/all/\" + str(size) + \"/\" + model_type\n",
    "            if not os.path.exists(image_path):\n",
    "                os.makedirs(image_path)\n",
    "\n",
    "            time_results = {\n",
    "                \"fit_time\": fit_time,\n",
    "                \"pred_time\": pred_time\n",
    "            }\n",
    "            \n",
    "            with open(image_path + \"/time.json\", \"w\") as outfile: \n",
    "                json.dump(time_results, outfile)\n",
    "\n",
    "            # Évaluez les performances  des modèles\n",
    "            if model_type==\"svm\":\n",
    "                \n",
    "                accuracy = accuracy_score(DataSet['Y_test_svm'], predictions)\n",
    "                print(f\"{model_type}: Accuracy = {accuracy}\")\n",
    "                print('\\n')\n",
    "\n",
    "                report = classification_report(DataSet['Y_test_svm'], predictions, target_names=label, output_dict=True)\n",
    "                sns.heatmap(pd.DataFrame(report).iloc[:-1, :].T, annot=True)\n",
    "                plt.savefig(image_path + \"/classification_report.png\")\n",
    "\n",
    "                plot_confusion_matrix(DataSet['Y_test_svm'], predictions, label, is_svm=True)\n",
    "                plt.savefig(image_path + \"/confusion_matrix.png\")\n",
    "                plt.show()\n",
    "                \n",
    "                plot_learning_curve_f1(model, subset_X_train, subset_Y_train_svm, cv=5)\n",
    "                plt.savefig(image_path + \"/f1_curve.png\")\n",
    "                plt.show()\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                accuracy = accuracy_score(DataSet['Y_test'], predictions)\n",
    "                print(f\"{model_type}: Accuracy = {accuracy}\")\n",
    "\n",
    "                report = classification_report(DataSet['Y_test'], predictions, target_names=label, output_dict=True)\n",
    "                sns.heatmap(pd.DataFrame(report).iloc[:-1, :].T, annot=True)\n",
    "                plt.savefig(image_path + \"/classification_report.png\")\n",
    "                \n",
    "                plot_confusion_matrix(DataSet['Y_test'].to_numpy(),predictions, label)\n",
    "                plt.savefig(image_path + \"/confusion_matrix.png\")\n",
    "                plt.show()\n",
    "                \n",
    "                plot_learning_curve_f1(model, subset_X_train, subset_Y_train, cv=5)\n",
    "                plt.savefig(image_path + \"/f1_curve.png\")\n",
    "                plt.show()\n",
    "        \n",
    "                \n",
    "\n",
    "            # Stockez les résultats dans le dictionnaire\n",
    "            key = f\"{model_type}_size_{size}\"\n",
    "            performance_results[key]=model_dict\n",
    "            \n",
    "    return performance_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/octave/work/protection-des-donnees-projet/src/concat.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/octave/work/protection-des-donnees-projet/src/concat.ipynb#X66sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m evaluate_models(DataSet)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate_models' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_models(DataSet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
